{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "XhTzomHB0bjQ",
      "metadata": {
        "id": "XhTzomHB0bjQ"
      },
      "source": [
        "# Hospital Management RAG Chatbot\n",
        "\n",
        "This notebook sets up Postgres, Milvus schema retrieval, Gemini based SQL generation, and a Streamlit admin UI.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0NXz2Bhp0bjT",
      "metadata": {
        "id": "0NXz2Bhp0bjT"
      },
      "outputs": [],
      "source": [
        "!pip -q install --upgrade pip\n",
        "!pip -q install streamlit google-generativeai python-dotenv pymilvus sqlalchemy psycopg2-binary langchain langchain-google-genai langchain-community sentence-transformers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MpxvK-d20bjV",
      "metadata": {
        "id": "MpxvK-d20bjV"
      },
      "source": [
        "## Set secrets as environment variables\n",
        "\n",
        "Fill these values, then run the cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KRO7kCUy0bjW",
      "metadata": {
        "id": "KRO7kCUy0bjW"
      },
      "outputs": [],
      "source": [
        "#ssh -p 443 -R0:localhost:5432 tcp@free.pinggy.io\n",
        "import os\n",
        "\n",
        "os.environ[\"REAL_HOST\"] = \"\"\n",
        "os.environ[\"REAL_PORT\"] = \"\"\n",
        "os.environ[\"PG_PASSWORD\"] = \"\"\n",
        "os.environ[\"PG_DB\"] = \"hospital\"\n",
        "os.environ[\"PG_USER\"] = \"postgres\"\n",
        "\n",
        "os.environ[\"MILVUS_URI\"] = \"\"\n",
        "os.environ[\"MILVUS_TOKEN\"] = \"\"\n",
        "\n",
        "os.environ[\"GEMINI_API_KEY\"] = \"\"\n",
        "os.environ[\"GEMINI_SQL_MODEL\"] = \"models/gemini-2.5-flash\"\n",
        "\n",
        "os.environ[\"MILVUS_COLLECTION\"] = \"db_schema_docs\"\n",
        "os.environ[\"EMBED_DIM\"] = \"768\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cjpsVK8I0bjW",
      "metadata": {
        "id": "cjpsVK8I0bjW"
      },
      "source": [
        "## Write backend module\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "SqZOU51g0bjX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqZOU51g0bjX",
        "outputId": "5cb1f697-9e36-42ac-ec9f-d423badc88f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote hospital_management_chatbot.py with all fixes applied.\n"
          ]
        }
      ],
      "source": [
        "backend_code = r'''import os\n",
        "import re\n",
        "import time\n",
        "from typing import List, Tuple, Dict, Any, Optional\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "from sqlalchemy import create_engine, text, inspect\n",
        "\n",
        "from pymilvus import connections, utility, FieldSchema, CollectionSchema, DataType, Collection\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.api_core.exceptions import TooManyRequests, ServiceUnavailable\n",
        "\n",
        "try:\n",
        "    from zoneinfo import ZoneInfo\n",
        "    _DHAKA_TZ = ZoneInfo(\"Asia/Dhaka\")\n",
        "except Exception:\n",
        "    _DHAKA_TZ = None\n",
        "\n",
        "\n",
        "def build_engine() -> Any:\n",
        "    real_host = os.getenv(\"REAL_HOST\", \"\")\n",
        "    real_port = os.getenv(\"REAL_PORT\", \"\")\n",
        "    password = os.getenv(\"PG_PASSWORD\", \"\")\n",
        "    db_name = os.getenv(\"PG_DB\", \"hospital\")\n",
        "    user = os.getenv(\"PG_USER\", \"postgres\")\n",
        "\n",
        "    if not real_host or not real_port or not password:\n",
        "        raise ValueError(\"Missing Postgres env vars REAL_HOST, REAL_PORT, PG_PASSWORD\")\n",
        "\n",
        "    database_url = f\"postgresql://{user}:{password}@{real_host}:{real_port}/{db_name}\"\n",
        "    return create_engine(\n",
        "        database_url,\n",
        "        pool_pre_ping=True,\n",
        "        connect_args={\"connect_timeout\": 10},\n",
        "    )\n",
        "\n",
        "\n",
        "def build_milvus_collection(collection_name: str, embed_dim: int) -> Collection:\n",
        "    uri = os.getenv(\"MILVUS_URI\", \"\")\n",
        "    token = os.getenv(\"MILVUS_TOKEN\", \"\")\n",
        "\n",
        "    if not uri or not token:\n",
        "        raise ValueError(\"Missing Milvus env vars MILVUS_URI, MILVUS_TOKEN\")\n",
        "\n",
        "    connections.connect(alias=\"default\", uri=uri, token=token)\n",
        "\n",
        "    expected_fields = [\n",
        "        \"id\", \"embedding\", \"doc_type\", \"table_name\",\n",
        "        \"contains_phi\", \"hospital_scoped\", \"schema_version\", \"text\"\n",
        "    ]\n",
        "\n",
        "    if utility.has_collection(collection_name):\n",
        "        col = Collection(collection_name)\n",
        "        existing_fields = [f.name for f in col.schema.fields]\n",
        "        if existing_fields != expected_fields:\n",
        "            utility.drop_collection(collection_name)\n",
        "        else:\n",
        "            col.load()\n",
        "            return col\n",
        "\n",
        "    fields = [\n",
        "        FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=True),\n",
        "        FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=embed_dim),\n",
        "        FieldSchema(name=\"doc_type\", dtype=DataType.VARCHAR, max_length=32),\n",
        "        FieldSchema(name=\"table_name\", dtype=DataType.VARCHAR, max_length=128),\n",
        "        FieldSchema(name=\"contains_phi\", dtype=DataType.BOOL),\n",
        "        FieldSchema(name=\"hospital_scoped\", dtype=DataType.BOOL),\n",
        "        FieldSchema(name=\"schema_version\", dtype=DataType.VARCHAR, max_length=64),\n",
        "        FieldSchema(name=\"text\", dtype=DataType.VARCHAR, max_length=8192),\n",
        "    ]\n",
        "    schema = CollectionSchema(fields, description=\"Schema docs for SQL generation\")\n",
        "    col = Collection(collection_name, schema=schema)\n",
        "\n",
        "    index_params = {\n",
        "        \"index_type\": \"HNSW\",\n",
        "        \"metric_type\": \"COSINE\",\n",
        "        \"params\": {\"M\": 16, \"efConstruction\": 200},\n",
        "    }\n",
        "    col.create_index(field_name=\"embedding\", index_params=index_params)\n",
        "    col.load()\n",
        "    return col\n",
        "\n",
        "\n",
        "def build_embedder() -> Any:\n",
        "    return SentenceTransformer(\"intfloat/e5-base-v2\")\n",
        "\n",
        "\n",
        "def embed_text(embedder: Any, s: str) -> List[float]:\n",
        "    vec = embedder.encode([s], normalize_embeddings=True)[0]\n",
        "    return vec.tolist()\n",
        "\n",
        "\n",
        "def _common_joins_for_table(table_name: str) -> List[str]:\n",
        "    join_map = {\n",
        "        \"admissions\": [\n",
        "            \"admissions.patient_id -> patients.patient_id\",\n",
        "            \"admissions.department_id -> departments.department_id\",\n",
        "            \"admissions.ward_id -> wards.ward_id\",\n",
        "            \"admissions.room_id -> rooms.room_id\",\n",
        "            \"admissions.bed_id -> beds.bed_id\",\n",
        "            \"admissions.attending_doctor_id -> staff.staff_id\",\n",
        "        ],\n",
        "        \"discharges\": [\"discharges.admission_id -> admissions.admission_id\"],\n",
        "        \"diagnoses\": [\"diagnoses.admission_id -> admissions.admission_id\"],\n",
        "        \"patient_conditions\": [\"patient_conditions.admission_id -> admissions.admission_id\"],\n",
        "        \"patient_vitals\": [\"patient_vitals.admission_id -> admissions.admission_id\"],\n",
        "        \"prescriptions\": [\n",
        "            \"prescriptions.admission_id -> admissions.admission_id\",\n",
        "            \"prescriptions.prescribed_by_staff_id -> staff.staff_id\",\n",
        "        ],\n",
        "        \"prescription_items\": [\n",
        "            \"prescription_items.prescription_id -> prescriptions.prescription_id\",\n",
        "            \"prescription_items.medication_id -> medications.medication_id\",\n",
        "        ],\n",
        "        \"nurse_assignments\": [\n",
        "            \"nurse_assignments.admission_id -> admissions.admission_id\",\n",
        "            \"nurse_assignments.nurse_staff_id -> staff.staff_id\",\n",
        "        ],\n",
        "        \"births\": [\n",
        "            \"births.mother_patient_id -> patients.patient_id\",\n",
        "            \"births.admission_id -> admissions.admission_id\",\n",
        "            \"births.doctor_staff_id -> staff.staff_id\",\n",
        "        ],\n",
        "        \"newborns\": [\"newborns.birth_id -> births.birth_id\"],\n",
        "        \"abortion_cases\": [\n",
        "            \"abortion_cases.patient_id -> patients.patient_id\",\n",
        "            \"abortion_cases.admission_id -> admissions.admission_id\",\n",
        "            \"abortion_cases.performed_by_staff_id -> staff.staff_id\",\n",
        "        ],\n",
        "        \"donations\": [\n",
        "            \"donations.donor_id -> donors.donor_id\",\n",
        "            \"donations.recipient_patient_id -> patients.patient_id\",\n",
        "        ],\n",
        "        \"organ_donation_items\": [\n",
        "            \"organ_donation_items.donation_id -> donations.donation_id\",\n",
        "            \"organ_donation_items.organ_id -> organs.organ_id\",\n",
        "        ],\n",
        "        \"surgeries\": [\"surgeries.admission_id -> admissions.admission_id\"],\n",
        "        \"surgery_team\": [\n",
        "            \"surgery_team.surgery_id -> surgeries.surgery_id\",\n",
        "            \"surgery_team.staff_id -> staff.staff_id\",\n",
        "        ],\n",
        "        \"blood_bank_inventory\": [\n",
        "            \"blood_bank_inventory.blood_group_id -> blood_groups.blood_group_id\"\n",
        "        ],\n",
        "        \"staff_department\": [\n",
        "            \"staff_department.staff_id -> staff.staff_id\",\n",
        "            \"staff_department.department_id -> departments.department_id\",\n",
        "        ],\n",
        "        \"staff_shifts\": [\n",
        "            \"staff_shifts.staff_id -> staff.staff_id\",\n",
        "            \"staff_shifts.department_id -> departments.department_id\",\n",
        "        ],\n",
        "    }\n",
        "    return join_map.get(table_name, [])\n",
        "\n",
        "\n",
        "def build_table_doc(inspector, table_name: str) -> str:\n",
        "    cols = inspector.get_columns(table_name)\n",
        "    pk = inspector.get_pk_constraint(table_name).get(\"constrained_columns\", [])\n",
        "    fks = inspector.get_foreign_keys(table_name)\n",
        "\n",
        "    lines = []\n",
        "    lines.append(\"doc_type: table\")\n",
        "    lines.append(f\"table: {table_name}\")\n",
        "    lines.append(f\"primary_key: {', '.join(pk) if pk else 'none'}\")\n",
        "    lines.append(\"columns:\")\n",
        "    for c in cols:\n",
        "        nn = \"not null\" if not c.get(\"nullable\", True) else \"nullable\"\n",
        "        lines.append(f\"  {c['name']} {str(c['type'])} {nn}\")\n",
        "    lines.append(\"foreign_keys:\")\n",
        "    if not fks:\n",
        "        lines.append(\"  none\")\n",
        "    else:\n",
        "        for fk in fks:\n",
        "            src_cols = \", \".join(fk.get(\"constrained_columns\", []))\n",
        "            ref_table = fk.get(\"referred_table\")\n",
        "            ref_cols = \", \".join(fk.get(\"referred_columns\", []))\n",
        "            lines.append(f\"  {table_name}.{src_cols} -> {ref_table}.{ref_cols}\")\n",
        "\n",
        "    joins = _common_joins_for_table(table_name)\n",
        "    if joins:\n",
        "        lines.append(\"common_joins:\")\n",
        "        for j in joins:\n",
        "            lines.append(f\"  {j}\")\n",
        "\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "\n",
        "def table_contains_phi(table_name: str) -> bool:\n",
        "    return table_name in {\n",
        "        \"patients\",\n",
        "        \"admissions\",\n",
        "        \"discharges\",\n",
        "        \"diagnoses\",\n",
        "        \"patient_conditions\",\n",
        "        \"patient_vitals\",\n",
        "        \"prescriptions\",\n",
        "        \"prescription_items\",\n",
        "        \"nurse_assignments\",\n",
        "        \"births\",\n",
        "        \"newborns\",\n",
        "        \"abortion_cases\",\n",
        "        \"donations\",\n",
        "        \"donors\",\n",
        "        \"surgeries\",\n",
        "        \"surgery_team\",\n",
        "        \"organ_donation_items\",\n",
        "    }\n",
        "\n",
        "\n",
        "def index_schema(engine, schema_col: Collection, embedder, schema_version: str = \"v1\") -> int:\n",
        "    inspector = inspect(engine)\n",
        "    tables = inspector.get_table_names()\n",
        "\n",
        "    schema_col.delete(expr=\"id >= 0\")\n",
        "    schema_col.flush()\n",
        "\n",
        "    embeddings = []\n",
        "    doc_type = []\n",
        "    table_name = []\n",
        "    contains_phi = []\n",
        "    hospital_scoped = []\n",
        "    schema_versions = []\n",
        "    text_docs = []\n",
        "\n",
        "    for t in tables:\n",
        "        doc = build_table_doc(inspector, t)\n",
        "        emb = embed_text(embedder, doc)\n",
        "\n",
        "        embeddings.append(emb)\n",
        "        doc_type.append(\"table\")\n",
        "        table_name.append(t)\n",
        "        contains_phi.append(bool(table_contains_phi(t)))\n",
        "        hospital_scoped.append(\"hospital_id\" in [c[\"name\"] for c in inspector.get_columns(t)])\n",
        "        schema_versions.append(schema_version)\n",
        "        text_docs.append(doc)\n",
        "\n",
        "    schema_col.insert([embeddings, doc_type, table_name, contains_phi, hospital_scoped, schema_versions, text_docs])\n",
        "    schema_col.flush()\n",
        "    return len(tables)\n",
        "\n",
        "\n",
        "def retrieve_schema(schema_col: Collection, embedder, question: str, top_k: int = 12) -> List[Tuple[str, str]]:\n",
        "    q_emb = embed_text(embedder, question)\n",
        "    res = schema_col.search(\n",
        "        data=[q_emb],\n",
        "        anns_field=\"embedding\",\n",
        "        param={\"params\": {\"ef\": 128}},\n",
        "        limit=top_k,\n",
        "        output_fields=[\"table_name\", \"text\"],\n",
        "    )\n",
        "    return [(h.entity.get(\"table_name\"), h.entity.get(\"text\")) for h in res[0]]\n",
        "\n",
        "\n",
        "def _ensure_tables(schema_col: Collection, embedder, schema_hits: List[Tuple[str, str]], must_have: List[str]) -> List[Tuple[str, str]]:\n",
        "    have = {t for t, _ in schema_hits}\n",
        "    out = list(schema_hits)\n",
        "    for t in must_have:\n",
        "        if t in have:\n",
        "            continue\n",
        "        extra = retrieve_schema(schema_col, embedder, f\"table: {t}\", top_k=3)\n",
        "        for et, edoc in extra:\n",
        "            if et == t and et not in have and edoc:\n",
        "                out.append((et, edoc))\n",
        "                have.add(et)\n",
        "                break\n",
        "    return out\n",
        "\n",
        "\n",
        "def build_schema_context(schema_hits: List[Tuple[str, str]]) -> str:\n",
        "    return \"\\n\\n\".join([doc for _, doc in schema_hits if doc])\n",
        "\n",
        "\n",
        "def safe_generate(model, prompt: str, max_retries: int = 8) -> str:\n",
        "    last_err = None\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            resp = model.generate_content(prompt, request_options={\"timeout\": 120})\n",
        "            return (resp.text or \"\").strip()\n",
        "        except (TooManyRequests, ServiceUnavailable) as e:\n",
        "            last_err = e\n",
        "            time.sleep(min(60, (2 ** attempt) + 0.25))\n",
        "        except Exception as e:\n",
        "            last_err = e\n",
        "            msg = str(e)\n",
        "            if (\"RemoteDisconnected\" in msg) or (\"Connection aborted\" in msg) or (\"EOF\" in msg):\n",
        "                time.sleep(min(60, (2 ** attempt) + 0.5))\n",
        "                continue\n",
        "            raise\n",
        "    raise RuntimeError(f\"LLM failed after retries. Last error was: {last_err}\")\n",
        "\n",
        "\n",
        "SQL_CACHE: Dict[str, str] = {}\n",
        "_LAST_LLM_CALL_TS = 0.0\n",
        "\n",
        "FORBIDDEN = {\n",
        "    \"insert\", \"update\", \"delete\", \"drop\", \"alter\", \"truncate\", \"create\",\n",
        "    \"grant\", \"revoke\", \"vacuum\", \"copy\"\n",
        "}\n",
        "\n",
        "\n",
        "def sanitize_sql(sql: str) -> str:\n",
        "    s = (sql or \"\").strip()\n",
        "    s = re.sub(r\"^```[a-zA-Z]*\\s*\", \"\", s).strip()\n",
        "    s = re.sub(r\"\\s*```$\", \"\", s).strip()\n",
        "    s = re.sub(r\";+\\s*$\", \"\", s).strip()\n",
        "    return s\n",
        "\n",
        "\n",
        "def extract_cte_names(sql: str) -> set:\n",
        "    s = re.sub(r\"\\s+\", \" \", (sql or \"\").strip()).strip().lower()\n",
        "    if not s.startswith(\"with \"):\n",
        "        return set()\n",
        "\n",
        "    ctes = set()\n",
        "    for m in re.finditer(r\"\\bwith\\s+([a-zA-Z_]\\w*)\\s+as\\s*\\(|\\)\\s*,\\s*([a-zA-Z_]\\w*)\\s+as\\s*\\(\", s):\n",
        "        if m.group(1):\n",
        "            ctes.add(m.group(1))\n",
        "        if m.group(2):\n",
        "            ctes.add(m.group(2))\n",
        "    return ctes\n",
        "\n",
        "\n",
        "def extract_table_names(sql: str) -> set:\n",
        "    s = re.sub(r\"\\s+\", \" \", (sql or \"\").strip().lower())\n",
        "    ctes = extract_cte_names(sql)\n",
        "\n",
        "    tables = set()\n",
        "    for m in re.finditer(r\"\\b(from|join)\\s+([a-zA-Z_][\\w]*)\", s):\n",
        "        t = m.group(2)\n",
        "        t = t.split(\".\")[-1].strip('\"')\n",
        "        if t and (t not in ctes):\n",
        "            tables.add(t)\n",
        "    return tables\n",
        "\n",
        "\n",
        "def validate_sql(sql: str, allowed_tables: List[str]):\n",
        "    s = (sql or \"\").strip()\n",
        "    if not s:\n",
        "        raise ValueError(\"Empty SQL\")\n",
        "    if \";\" in s:\n",
        "        raise ValueError(\"Semicolons not allowed\")\n",
        "    low = s.lower()\n",
        "    if not (low.startswith(\"select\") or low.startswith(\"with\")):\n",
        "        raise ValueError(\"Only SELECT or WITH allowed\")\n",
        "    for kw in FORBIDDEN:\n",
        "        if re.search(rf\"\\b{kw}\\b\", low):\n",
        "            raise ValueError(\"Forbidden SQL keyword found\")\n",
        "    if \":hospital_id\" not in s:\n",
        "        raise ValueError(\"Missing required :hospital_id parameter\")\n",
        "\n",
        "    used = extract_table_names(s)\n",
        "    unknown = used.difference(set(allowed_tables))\n",
        "    if unknown:\n",
        "        raise ValueError(f\"SQL references tables not in retrieved schema: {sorted(list(unknown))}\")\n",
        "\n",
        "\n",
        "def extract_alias_map(sql: str) -> Dict[str, str]:\n",
        "    s = re.sub(r\"\\s+\", \" \", sql.strip())\n",
        "    alias_map = {}\n",
        "    pattern = re.compile(r\"\\b(from|join)\\s+([a-zA-Z_][\\w]*)\\s*(?:as\\s+)?([a-zA-Z_][\\w]*)?\\b\", re.IGNORECASE)\n",
        "    for m in pattern.finditer(s):\n",
        "        table = m.group(2)\n",
        "        alias = m.group(3) or table\n",
        "        alias_map[alias] = table\n",
        "    return alias_map\n",
        "\n",
        "\n",
        "def get_table_columns(engine, table_name: str) -> set:\n",
        "    inspector = inspect(engine)\n",
        "    return {c[\"name\"] for c in inspector.get_columns(table_name)}\n",
        "\n",
        "\n",
        "def _parse_qualified_identifiers(sql: str) -> List[Tuple[str, str]]:\n",
        "    s = re.sub(r\"\\s+\", \" \", (sql or \"\").strip())\n",
        "    alias_map = extract_alias_map(s)\n",
        "    pairs = []\n",
        "    for m in re.finditer(r\"\\b([a-zA-Z_]\\w*)\\.([a-zA-Z_]\\w*)\\b\", s):\n",
        "        alias = m.group(1)\n",
        "        col = m.group(2)\n",
        "        table = alias_map.get(alias)\n",
        "        if table:\n",
        "            pairs.append((table, col))\n",
        "    return pairs\n",
        "\n",
        "\n",
        "def validate_columns(engine, sql: str) -> None:\n",
        "    pairs = _parse_qualified_identifiers(sql)\n",
        "    cache: Dict[str, set] = {}\n",
        "    for table, col in pairs:\n",
        "        if table not in cache:\n",
        "            cache[table] = get_table_columns(engine, table)\n",
        "        if col not in cache[table]:\n",
        "            raise ValueError(f\"Unknown column, {table}.{col}\")\n",
        "\n",
        "\n",
        "def remove_invalid_hospital_filters(engine, sql: str) -> str:\n",
        "    alias_map = extract_alias_map(sql)\n",
        "    bad_aliases = []\n",
        "    for alias, table in alias_map.items():\n",
        "        cols = get_table_columns(engine, table)\n",
        "        if \"hospital_id\" not in cols:\n",
        "            bad_aliases.append(alias)\n",
        "\n",
        "    if not bad_aliases:\n",
        "        return sql\n",
        "\n",
        "    fixed = sql\n",
        "    for a in bad_aliases:\n",
        "        fixed = re.sub(rf\"\\s+AND\\s+{a}\\.hospital_id\\s*=\\s*:hospital_id\\b\", \"\", fixed, flags=re.IGNORECASE)\n",
        "        fixed = re.sub(rf\"\\b{a}\\.hospital_id\\s*=\\s*:hospital_id\\s+AND\\s+\", \"\", fixed, flags=re.IGNORECASE)\n",
        "        fixed = re.sub(rf\"\\b{a}\\.hospital_id\\s*=\\s*:hospital_id\\b\", \"TRUE\", fixed, flags=re.IGNORECASE)\n",
        "\n",
        "    fixed = re.sub(r\"WHERE\\s+TRUE\\s+AND\\s+\", \"WHERE \", fixed, flags=re.IGNORECASE)\n",
        "    fixed = re.sub(r\"WHERE\\s+TRUE\\s*$\", \"\", fixed, flags=re.IGNORECASE)\n",
        "    return fixed\n",
        "\n",
        "\n",
        "def execute_sql(engine, sql: str, hospital_id: int, extra_params: Optional[Dict[str, Any]] = None, max_rows: int = 200) -> List[Dict[str, Any]]:\n",
        "    wrapped = f\"WITH q AS ({sql}) SELECT * FROM q LIMIT :_limit\"\n",
        "    params: Dict[str, Any] = {\"hospital_id\": hospital_id, \"_limit\": max_rows}\n",
        "    if extra_params:\n",
        "        params.update(extra_params)\n",
        "\n",
        "    with engine.connect() as conn:\n",
        "        rows = conn.execute(text(wrapped), params).mappings().all()\n",
        "    return [dict(r) for r in rows]\n",
        "\n",
        "\n",
        "def summarize_rows(rows: List[Dict[str, Any]]) -> str:\n",
        "    if not rows:\n",
        "        return \"No matching records found.\"\n",
        "\n",
        "    cols = list(rows[0].keys())\n",
        "\n",
        "    if len(rows) <= 10:\n",
        "        return \"\\n\".join([\", \".join([f\"{k}: {r.get(k)}\" for k in cols]) for r in rows])\n",
        "\n",
        "    head = f\"Summary, {len(rows)} rows returned. Showing first 10.\"\n",
        "    body = \"\\n\".join([\", \".join([f\"{k}: {r.get(k)}\" for k in cols]) for r in rows[:10]])\n",
        "    return head + \"\\n\" + body\n",
        "\n",
        "\n",
        "def build_gemini_model() -> Any:\n",
        "    api_key = os.getenv(\"GEMINI_API_KEY\", \"\")\n",
        "    if not api_key:\n",
        "        raise ValueError(\"Missing GEMINI_API_KEY env var\")\n",
        "    genai.configure(api_key=api_key)\n",
        "    model_name = os.getenv(\"GEMINI_SQL_MODEL\", \"models/gemini-2.0-flash-lite-001\")\n",
        "    return genai.GenerativeModel(model_name)\n",
        "\n",
        "\n",
        "_INTENTS = [\n",
        "    (\"ADMISSIONS_BY_DEPARTMENT\", [r\"\\badmit\", r\"\\bdepartment\\b\"], [\"admissions\", \"departments\"]),\n",
        "    (\"ADMISSIONS_DAILY_SERIES\", [r\"\\badmit\", r\"last\\s+\\d+\\s+days|last\\s+7\\s+days|daily\"], [\"admissions\"]),\n",
        "    (\"ADMISSIONS_TODAY\", [r\"\\badmit\", r\"\\btoday\\b\"], [\"admissions\"]),\n",
        "    (\"CURRENT_ADMITTED_LIST\", [r\"\\bcurrently\\b|\\bcurrent\\b\", r\"\\badmitted\\b\"], [\"admissions\", \"patients\", \"departments\", \"wards\", \"rooms\", \"beds\"]),\n",
        "    (\"DISCHARGES\", [r\"\\bdischarg\"], [\"discharges\", \"admissions\", \"patients\"]),\n",
        "    (\"CRITICAL_PATIENTS\", [r\"\\bcritical\\b\"], [\"patient_conditions\", \"admissions\", \"patients\", \"departments\"]),\n",
        "    (\"VITALS\", [r\"\\bvitals?\\b\"], [\"patient_vitals\", \"admissions\", \"patients\"]),\n",
        "    (\"BIRTHS\", [r\"\\bbirths?\\b|\\bbabies\\b\"], [\"births\", \"newborns\", \"patients\"]),\n",
        "    (\"ABORTION\", [r\"\\babortion\\b\"], [\"abortion_cases\", \"patients\", \"staff\"]),\n",
        "    (\"STAFF_COUNTS\", [r\"\\bstaff\\b\", r\"\\brole\\b|by\\s+role|distribution\"], [\"staff\", \"staff_roles\", \"staff_department\", \"departments\"]),\n",
        "    (\"SHIFTS\", [r\"\\bshift\\b|\\bavailability\\b|on\\s+shift\"], [\"staff_shifts\", \"staff\", \"staff_roles\", \"departments\"]),\n",
        "    (\"PRESCRIPTIONS\", [r\"\\bprescription|\\bmedication\"], [\"prescriptions\", \"prescription_items\", \"medications\", \"admissions\", \"patients\", \"staff\"]),\n",
        "    (\"NURSE_ASSIGNMENTS\", [r\"\\bnurse\\b\", r\"\\bassign\"], [\"nurse_assignments\", \"admissions\", \"patients\", \"staff\", \"wards\", \"rooms\", \"beds\"]),\n",
        "    (\"BLOOD_BANK\", [r\"\\bblood\\b\"], [\"blood_bank_inventory\", \"blood_groups\", \"donors\", \"donations\", \"patients\"]),\n",
        "    (\"ORGAN_DONATION\", [r\"\\borgan\\b\"], [\"donations\", \"organ_donation_items\", \"organs\", \"donors\"]),\n",
        "    (\"SURGERY\", [r\"\\bsurger\"], [\"surgeries\", \"surgery_team\", \"admissions\", \"patients\", \"staff\"]),\n",
        "]\n",
        "\n",
        "\n",
        "def detect_intent(question: str) -> Tuple[str, List[str]]:\n",
        "    q = (question or \"\").lower()\n",
        "    for name, patterns, must_tables in _INTENTS:\n",
        "        ok = True\n",
        "        for p in patterns:\n",
        "            if not re.search(p, q):\n",
        "                ok = False\n",
        "                break\n",
        "        if ok:\n",
        "            return name, must_tables\n",
        "    return \"GENERAL\", []\n",
        "\n",
        "\n",
        "def _parse_iso_dt(s: str) -> Optional[datetime]:\n",
        "    s2 = (s or \"\").strip()\n",
        "    s2 = s2.replace(\" \", \"T\")\n",
        "    try:\n",
        "        dt = datetime.fromisoformat(s2)\n",
        "        return dt\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "def get_db_now(engine) -> Optional[datetime]:\n",
        "    try:\n",
        "        with engine.connect() as conn:\n",
        "            dt = conn.execute(text(\"SELECT max(admitted_ts) FROM admissions\")).scalar()\n",
        "            return dt\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "def resolve_time_window(question: str, engine) -> Dict[str, Any]:\n",
        "    q = (question or \"\").lower()\n",
        "\n",
        "    db_now = get_db_now(engine)\n",
        "    if db_now is not None:\n",
        "        now = db_now\n",
        "    else:\n",
        "        now = datetime.now(_DHAKA_TZ) if _DHAKA_TZ else datetime.now()\n",
        "\n",
        "    m_iso = re.search(r\"(\\d{4}-\\d{2}-\\d{2}\\s+\\d{2}:\\d{2}:\\d{2}(?:\\+\\d{2}:\\d{2})?)\", question or \"\")\n",
        "    if m_iso:\n",
        "        dt = _parse_iso_dt(m_iso.group(1))\n",
        "        if dt:\n",
        "            return {\"at_ts\": dt}\n",
        "\n",
        "    if re.search(r\"\\btoday\\b\", q):\n",
        "        start = now.replace(hour=0, minute=0, second=0, microsecond=0)\n",
        "        end = start + timedelta(days=1)\n",
        "        return {\"start_ts\": start, \"end_ts\": end}\n",
        "\n",
        "    if re.search(r\"\\bthis\\s+month\\b\", q):\n",
        "        start = now.replace(day=1, hour=0, minute=0, second=0, microsecond=0)\n",
        "        if start.month == 12:\n",
        "            end = start.replace(year=start.year + 1, month=1)\n",
        "        else:\n",
        "            end = start.replace(month=start.month + 1)\n",
        "        return {\"start_ts\": start, \"end_ts\": end}\n",
        "\n",
        "    m = re.search(r\"last\\s+(\\d+)\\s+days\", q)\n",
        "    if m:\n",
        "        n = int(m.group(1))\n",
        "        end = now\n",
        "        start = now - timedelta(days=n)\n",
        "        return {\"start_ts\": start, \"end_ts\": end}\n",
        "\n",
        "    if re.search(r\"last\\s+7\\s+days\", q):\n",
        "        end = now\n",
        "        start = now - timedelta(days=7)\n",
        "        return {\"start_ts\": start, \"end_ts\": end}\n",
        "\n",
        "    if re.search(r\"last\\s+30\\s+days\", q):\n",
        "        end = now\n",
        "        start = now - timedelta(days=30)\n",
        "        return {\"start_ts\": start, \"end_ts\": end}\n",
        "\n",
        "    return {}\n",
        "\n",
        "\n",
        "def generate_sql(model, question: str, schema_hits: List[Tuple[str, str]], intent: str, time_info: Dict[str, Any], error_hint: str = \"\") -> str:\n",
        "    schema_context = build_schema_context(schema_hits)\n",
        "\n",
        "    time_bucket = \"time\" if time_info else \"notime\"\n",
        "    cache_key = f\"{intent}:{hash(schema_context)}:{time_bucket}\"\n",
        "\n",
        "    if cache_key in SQL_CACHE and not error_hint:\n",
        "        return SQL_CACHE[cache_key]\n",
        "\n",
        "    time_rules = []\n",
        "    if \"start_ts\" in time_info and \"end_ts\" in time_info:\n",
        "        time_rules.append(\"If the question is time based, use :start_ts and :end_ts for filtering on the correct timestamp column.\")\n",
        "    if \"at_ts\" in time_info:\n",
        "        time_rules.append(\"If the question asks availability at a time, use :at_ts and compare it between shift start and end timestamps.\")\n",
        "    time_rule_text = \"\\n\".join(time_rules) if time_rules else \"If the question is time based, you may use NOW() but prefer provided parameters when available.\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You generate PostgreSQL SQL to be executed with SQLAlchemy.\n",
        "\n",
        "Rules\n",
        "1 Output exactly one SQL query\n",
        "2 Only SELECT or WITH is allowed\n",
        "3 Use only tables and columns present in the schema context\n",
        "4 Apply hospital filter only on tables that actually contain a hospital_id column\n",
        "5 Add LIMIT 200 for list queries\n",
        "6 Do not output semicolons or code fences\n",
        "7 Use :hospital_id placeholder, not a literal number\n",
        "8 {time_rule_text}\n",
        "9 Prefer join paths shown in common_joins if present\n",
        "10 When querying patient_conditions for current status, select the latest record per admission using max(updated_ts)\n",
        "\n",
        "Intent\n",
        "{intent}\n",
        "\n",
        "Schema context\n",
        "{schema_context}\n",
        "\n",
        "Question\n",
        "{question}\n",
        "\n",
        "{error_hint}\n",
        "\n",
        "Output only SQL\n",
        "\"\"\".strip()\n",
        "\n",
        "    sql = sanitize_sql(safe_generate(model, prompt))\n",
        "    if not error_hint:\n",
        "        SQL_CACHE[cache_key] = sql\n",
        "    return sql\n",
        "\n",
        "\n",
        "_ENGINE = None\n",
        "_SCHEMA_COL = None\n",
        "_EMBEDDER = None\n",
        "_GEMINI = None\n",
        "\n",
        "COLLECTION_NAME = os.getenv(\"MILVUS_COLLECTION\", \"db_schema_docs\")\n",
        "EMBED_DIM = int(os.getenv(\"EMBED_DIM\", \"768\"))\n",
        "\n",
        "\n",
        "def init_once(index: bool = False) -> None:\n",
        "    global _ENGINE, _SCHEMA_COL, _EMBEDDER, _GEMINI\n",
        "\n",
        "    if _ENGINE is None:\n",
        "        _ENGINE = build_engine()\n",
        "    if _SCHEMA_COL is None:\n",
        "        _SCHEMA_COL = build_milvus_collection(COLLECTION_NAME, EMBED_DIM)\n",
        "    if _EMBEDDER is None:\n",
        "        _EMBEDDER = build_embedder()\n",
        "    if _GEMINI is None:\n",
        "        _GEMINI = build_gemini_model()\n",
        "\n",
        "    if index:\n",
        "        index_schema(_ENGINE, _SCHEMA_COL, _EMBEDDER, schema_version=os.getenv(\"SCHEMA_VERSION\", \"v1\"))\n",
        "\n",
        "\n",
        "def chat(question: str, hospital_id: int) -> str:\n",
        "    init_once(index=False)\n",
        "\n",
        "    intent, must_tables = detect_intent(question)\n",
        "    time_info = resolve_time_window(question, _ENGINE)\n",
        "\n",
        "    schema_hits = retrieve_schema(_SCHEMA_COL, _EMBEDDER, question, top_k=12)\n",
        "    if must_tables:\n",
        "        schema_hits = _ensure_tables(_SCHEMA_COL, _EMBEDDER, schema_hits, must_tables)\n",
        "\n",
        "    allowed_tables = [t for t, _ in schema_hits]\n",
        "\n",
        "    extra_params: Dict[str, Any] = {}\n",
        "    if \"start_ts\" in time_info and \"end_ts\" in time_info:\n",
        "        extra_params[\"start_ts\"] = time_info[\"start_ts\"]\n",
        "        extra_params[\"end_ts\"] = time_info[\"end_ts\"]\n",
        "    if \"at_ts\" in time_info:\n",
        "        extra_params[\"at_ts\"] = time_info[\"at_ts\"]\n",
        "\n",
        "    global _LAST_LLM_CALL_TS\n",
        "    now_ts = time.time()\n",
        "    gap = now_ts - _LAST_LLM_CALL_TS\n",
        "    if gap < 1.2:\n",
        "        time.sleep(1.2 - gap)\n",
        "    _LAST_LLM_CALL_TS = time.time()\n",
        "\n",
        "    sql = generate_sql(_GEMINI, question, schema_hits, intent=intent, time_info=time_info)\n",
        "    sql = remove_invalid_hospital_filters(_ENGINE, sql)\n",
        "\n",
        "    try:\n",
        "        validate_sql(sql, allowed_tables=allowed_tables)\n",
        "        validate_columns(_ENGINE, sql)\n",
        "    except Exception as e:\n",
        "        hint = f\"Previous SQL failed validation because: {str(e)}. Regenerate SQL using only valid identifiers from schema context.\"\n",
        "        sql = generate_sql(_GEMINI, question, schema_hits, intent=intent, time_info=time_info, error_hint=hint)\n",
        "        sql = remove_invalid_hospital_filters(_ENGINE, sql)\n",
        "        validate_sql(sql, allowed_tables=allowed_tables)\n",
        "        validate_columns(_ENGINE, sql)\n",
        "\n",
        "    rows = execute_sql(_ENGINE, sql, hospital_id=hospital_id, extra_params=extra_params, max_rows=200)\n",
        "    return summarize_rows(rows)\n",
        "'''\n",
        "with open(\"hospital_management_chatbot.py\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(backend_code)\n",
        "print(\"Wrote hospital_management_chatbot.py with all fixes applied.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_UAXZWYH0bjY",
      "metadata": {
        "id": "_UAXZWYH0bjY"
      },
      "source": [
        "## Connectivity smoke tests\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "7HF-sGJ40bjZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HF-sGJ40bjZ",
        "outputId": "d4c807ca-bc39-45ca-e938-ede57b369ddf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Postgres OK: (1,)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from sqlalchemy import create_engine, text\n",
        "\n",
        "DATABASE_URL = f\"postgresql://{os.environ.get('PG_USER','postgres')}:{os.environ.get('PG_PASSWORD','')}@{os.environ.get('REAL_HOST','')}:{os.environ.get('REAL_PORT','')}/{os.environ.get('PG_DB','hospital')}\"\n",
        "engine = create_engine(DATABASE_URL, pool_pre_ping=True, connect_args={\"connect_timeout\": 10})\n",
        "with engine.connect() as c:\n",
        "    print(\"Postgres OK:\", c.execute(text(\"SELECT 1\")).fetchone())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7FwDgg3q0bja",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FwDgg3q0bja",
        "outputId": "ef461f82-74dc-4539-d229-7de743f484b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Milvus OK. Collections: ['db_schema_docs', 'db_schema_docs_v2']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pymilvus import connections, utility\n",
        "\n",
        "connections.connect(alias=\"default\", uri=os.environ[\"MILVUS_URI\"], token=os.environ[\"MILVUS_TOKEN\"])\n",
        "print(\"Milvus OK. Collections:\", utility.list_collections())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0XbtvYiI0bja",
      "metadata": {
        "id": "0XbtvYiI0bja"
      },
      "source": [
        "## Index schema into Milvus\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "-1C8mvJk0bjb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1C8mvJk0bjb",
        "outputId": "aeb719de-683f-4b25-b1fa-5376c9d64fce"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Schema indexed into Milvus\n"
          ]
        }
      ],
      "source": [
        "import os, importlib\n",
        "os.environ[\"MILVUS_COLLECTION\"] = \"db_schema_docs_v2\"\n",
        "\n",
        "import hospital_management_chatbot\n",
        "importlib.reload(hospital_management_chatbot)\n",
        "\n",
        "hospital_management_chatbot.init_once(index=True)\n",
        "print(\"Schema indexed into Milvus\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "RftsBAq-nujh",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RftsBAq-nujh",
        "outputId": "bf44054a-a1df-4e78-e338-8489cfcf4a17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PASS 1 How many patients were admitted today\n",
            "PASS 1 Daily admissions count for the last 7 days\n",
            "PASS 1 Admissions by department\n",
            "PASS 1 Which department has the highest admissions\n",
            "PASS 1 Most frequent admission reasons\n",
            "PASS 1 List currently admitted patients with department, ward, room, bed\n",
            "PASS 1 How many patients have been discharged\n",
            "PASS 1 Show the most recent discharged patients\n",
            "FAIL 1 Which patients are currently critical\n",
            "Error: LatestPatientCondition\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-2209618831.py\", line 43, in <cell line: 0>\n",
            "    out = chat(q, hospital_id=hid)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/hospital_management_chatbot.py\", line 659, in chat\n",
            "    sql = remove_invalid_hospital_filters(_ENGINE, sql)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/hospital_management_chatbot.py\", line 404, in remove_invalid_hospital_filters\n",
            "    cols = get_table_columns(engine, table)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/hospital_management_chatbot.py\", line 374, in get_table_columns\n",
            "    return {c[\"name\"] for c in inspector.get_columns(table_name)}\n",
            "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sqlalchemy/engine/reflection.py\", line 869, in get_columns\n",
            "    col_defs = self.dialect.get_columns(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<string>\", line 2, in get_columns\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sqlalchemy/engine/reflection.py\", line 106, in cache\n",
            "    ret = fn(self, con, *args, **kw)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packa\n",
            "FAIL 1 Latest vitals for critical patients\n",
            "Error: latest_critical_condition\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-2209618831.py\", line 43, in <cell line: 0>\n",
            "    out = chat(q, hospital_id=hid)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/hospital_management_chatbot.py\", line 659, in chat\n",
            "    sql = remove_invalid_hospital_filters(_ENGINE, sql)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/hospital_management_chatbot.py\", line 404, in remove_invalid_hospital_filters\n",
            "    cols = get_table_columns(engine, table)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/hospital_management_chatbot.py\", line 374, in get_table_columns\n",
            "    return {c[\"name\"] for c in inspector.get_columns(table_name)}\n",
            "                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sqlalchemy/engine/reflection.py\", line 869, in get_columns\n",
            "    col_defs = self.dialect.get_columns(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<string>\", line 2, in get_columns\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/sqlalchemy/engine/reflection.py\", line 106, in cache\n",
            "    ret = fn(self, con, *args, **kw)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packa\n",
            "PASS 1 How many babies were born today\n",
            "PASS 1 How many babies were born this month\n",
            "PASS 1 How many newborns died after birth\n",
            "PASS 1 How many abortion cases were performed this month\n",
            "PASS 1 List recent abortion cases with procedure type and date\n",
            "PASS 1 Total staff count by role\n",
            "PASS 1 Staff distribution by department and role\n",
            "PASS 1 Which doctors are on shift right now\n",
            "PASS 1 Top prescribed medications\n",
            "PASS 1 Nurse workload, number of active patients per nurse\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 629.95ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 580.48ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 605.17ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 630.11ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 605.66ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 629.83ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 755.79ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 910.83ms\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FAIL 1 Which blood groups are available and how many units\n",
            "Error: LLM failed after retries. Last error was: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n",
            "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\n",
            "Please retry in 39.97079067s.\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-2209618831.py\", line 43, in <cell line: 0>\n",
            "    out = chat(q, hospital_id=hid)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/hospital_management_chatbot.py\", line 658, in chat\n",
            "    sql = generate_sql(_GEMINI, question, schema_hits, intent=intent, time_info=time_info)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/hospital_management_chatbot.py\", line 601, in generate_sql\n",
            "    sql = sanitize_sql(safe_generate(model, prompt))\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/hospital_management_chatbot.py\", line 293, in safe_generate\n",
            "    raise RuntimeError(f\"LLM failed after retries. Last error was: {last_err}\")\n",
            "RuntimeError: LLM failed after retries. Last error was: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 907.88ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 606.58ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 605.70ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 630.60ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 605.40ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 606.65ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 657.38ms\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTooManyRequests\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/content/hospital_management_chatbot.py\u001b[0m in \u001b[0;36msafe_generate\u001b[0;34m(model, prompt, max_retries)\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m120\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/generativeai/generative_models.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                 response = self._client.generate_content(\n\u001b[0m\u001b[1;32m    332\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    834\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    836\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m             )\n\u001b[0;32m--> 294\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    295\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;31m# defer to shared logic for handling errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             next_sleep = _retry_error_helper(\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_base.py\u001b[0m in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    213\u001b[0m         )\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfinal_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msource_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mon_error_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   1160\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mcore_exceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_http_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTooManyRequests\u001b[0m: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\nPlease retry in 28.446060245s.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2209618831.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtests\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhospital_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/hospital_management_chatbot.py\u001b[0m in \u001b[0;36mchat\u001b[0;34m(question, hospital_id)\u001b[0m\n\u001b[1;32m    656\u001b[0m     \u001b[0m_LAST_LLM_CALL_TS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m     \u001b[0msql\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_GEMINI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema_hits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mintent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m     \u001b[0msql\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_invalid_hospital_filters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ENGINE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msql\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/hospital_management_chatbot.py\u001b[0m in \u001b[0;36mgenerate_sql\u001b[0;34m(model, question, schema_hits, intent, time_info, error_hint)\u001b[0m\n\u001b[1;32m    599\u001b[0m \"\"\".strip()\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m     \u001b[0msql\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msafe_generate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0merror_hint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m         \u001b[0mSQL_CACHE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msql\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/hospital_management_chatbot.py\u001b[0m in \u001b[0;36msafe_generate\u001b[0;34m(model, prompt, max_retries)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTooManyRequests\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mServiceUnavailable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0mlast_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mattempt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mlast_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import random, time\n",
        "from hospital_management_chatbot import chat, init_once\n",
        "import traceback\n",
        "\n",
        "init_once(index=False)\n",
        "\n",
        "tests = [\n",
        "    (\"How many patients were admitted today\", 1, \"count\"),\n",
        "    (\"Daily admissions count for the last 7 days\", 1, \"timeseries\"),\n",
        "    (\"Admissions by department\", 1, \"grouped\"),\n",
        "    (\"Which department has the highest admissions\", 1, \"single_row\"),\n",
        "    (\"Most frequent admission reasons\", 1, \"grouped\"),\n",
        "    (\"List currently admitted patients with department, ward, room, bed\", 1, \"list\"),\n",
        "    (\"How many patients have been discharged\", 1, \"count\"),\n",
        "    (\"Show the most recent discharged patients\", 1, \"list\"),\n",
        "    (\"Which patients are currently critical\", 1, \"list\"),\n",
        "    (\"Latest vitals for critical patients\", 1, \"list\"),\n",
        "    (\"How many babies were born today\", 1, \"count\"),\n",
        "    (\"How many babies were born this month\", 1, \"count\"),\n",
        "    (\"How many newborns died after birth\", 1, \"count\"),\n",
        "    (\"How many abortion cases were performed this month\", 1, \"count\"),\n",
        "    (\"List recent abortion cases with procedure type and date\", 1, \"list\"),\n",
        "    (\"Total staff count by role\", 1, \"grouped\"),\n",
        "    (\"Staff distribution by department and role\", 1, \"grouped\"),\n",
        "    (\"Which doctors are on shift right now\", 1, \"list\"),\n",
        "    (\"Top prescribed medications\", 1, \"grouped\"),\n",
        "    (\"Nurse workload, number of active patients per nurse\", 1, \"grouped\"),\n",
        "    (\"Which blood groups are available and how many units\", 1, \"list\"),\n",
        "    (\"Show scheduled surgeries with patient and lead surgeon\", 1, \"list\"),\n",
        "    (\"Admissions by department\", 2, \"grouped\"),\n",
        "    (\"Which blood groups are available\", 2, \"list\"),\n",
        "]\n",
        "\n",
        "def looks_like_count(text_out: str) -> bool:\n",
        "    low = (text_out or \"\").lower()\n",
        "    return (\"count\" in low) or (\"total\" in low) or low.strip().isdigit()\n",
        "\n",
        "passed = 0\n",
        "failed = 0\n",
        "\n",
        "for q, hid, kind in tests:\n",
        "    try:\n",
        "        out = chat(q, hospital_id=hid)\n",
        "\n",
        "        ok = True\n",
        "        if kind == \"count\":\n",
        "            ok = looks_like_count(out)\n",
        "        elif kind in {\"list\", \"grouped\", \"timeseries\", \"single_row\"}:\n",
        "            ok = out is not None and len(out.strip()) > 0\n",
        "\n",
        "        if ok:\n",
        "            print(\"PASS\", hid, q)\n",
        "            passed += 1\n",
        "        else:\n",
        "            print(\"FAIL\", hid, q)\n",
        "            print(\"Output:\", (out or \"\")[:600])\n",
        "            failed += 1\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"FAIL\", hid, q)\n",
        "        print(\"Error:\", str(e))\n",
        "        print(traceback.format_exc()[:1200])\n",
        "        failed += 1\n",
        "\n",
        "    time.sleep(1.0 + random.random() * 0.4)\n",
        "\n",
        "print(\"Done. Passed:\", passed, \"Failed:\", failed)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fbHQ1of0bjb",
      "metadata": {
        "id": "3fbHQ1of0bjb"
      },
      "source": [
        "## Test chat in notebook\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "5Fo1MQBl5HjF",
      "metadata": {
        "id": "5Fo1MQBl5HjF"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "M4h4iNlZ5IJU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "id": "M4h4iNlZ5IJU",
        "outputId": "b5dccb87-1cdd-4baf-ab4f-5e02ac5957a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "models/gemini-2.5-flash\n",
            "models/gemini-2.5-pro\n",
            "models/gemini-2.0-flash-exp\n",
            "models/gemini-2.0-flash\n",
            "models/gemini-2.0-flash-001\n",
            "models/gemini-2.0-flash-exp-image-generation\n",
            "models/gemini-2.0-flash-lite-001\n",
            "models/gemini-2.0-flash-lite\n",
            "models/gemini-2.0-flash-lite-preview-02-05\n",
            "models/gemini-2.0-flash-lite-preview\n",
            "models/gemini-exp-1206\n",
            "models/gemini-2.5-flash-preview-tts\n",
            "models/gemini-2.5-pro-preview-tts\n",
            "models/gemma-3-1b-it\n",
            "models/gemma-3-4b-it\n",
            "models/gemma-3-12b-it\n",
            "models/gemma-3-27b-it\n",
            "models/gemma-3n-e4b-it\n",
            "models/gemma-3n-e2b-it\n",
            "models/gemini-flash-latest\n",
            "models/gemini-flash-lite-latest\n",
            "models/gemini-pro-latest\n",
            "models/gemini-2.5-flash-lite\n",
            "models/gemini-2.5-flash-image-preview\n",
            "models/gemini-2.5-flash-image\n",
            "models/gemini-2.5-flash-preview-09-2025\n",
            "models/gemini-2.5-flash-lite-preview-09-2025\n",
            "models/gemini-3-pro-preview\n",
            "models/gemini-3-flash-preview\n",
            "models/gemini-3-pro-image-preview\n",
            "models/nano-banana-pro-preview\n",
            "models/gemini-robotics-er-1.5-preview\n",
            "models/gemini-2.5-computer-use-preview-10-2025\n",
            "models/deep-research-pro-preview-12-2025\n"
          ]
        }
      ],
      "source": [
        "models = genai.list_models()\n",
        "\n",
        "for m in models:\n",
        "    if \"generateContent\" in m.supported_generation_methods:\n",
        "        print(m.name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "XHpMZLXY0bjb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHpMZLXY0bjb",
        "outputId": "9198881e-9d57-41fb-e6ef-c7d71ebc5f3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "name: Cardiology, total_admissions: 1\n",
            "name: ICU, total_admissions: 1\n",
            "name: Obstetrics, total_admissions: 1\n"
          ]
        }
      ],
      "source": [
        "from hospital_management_chatbot import chat\n",
        "print(chat(\"Admissions by department\", hospital_id=1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QdP5oj260bjb",
      "metadata": {
        "id": "QdP5oj260bjb"
      },
      "source": [
        "## Write Streamlit app\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "2r2QV3Vz0bjb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2r2QV3Vz0bjb",
        "outputId": "2a4ab284-5939-4b8e-dddf-02c749475d6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wrote app.py\n"
          ]
        }
      ],
      "source": [
        "app_code = r'''import os\n",
        "import streamlit as st\n",
        "from datetime import datetime\n",
        "import concurrent.futures\n",
        "\n",
        "st.set_page_config(page_title=\"Hospital Admin Chatbot\", page_icon=\"\", layout=\"wide\")\n",
        "\n",
        "RED = \"#c1121f\"\n",
        "WHITE = \"#ffffff\"\n",
        "SOFT_RED = \"#ffe5e8\"\n",
        "DARK = \"#111111\"\n",
        "\n",
        "st.markdown(\n",
        "    f\"\"\"\n",
        "    <style>\n",
        "    .stApp {{ background: {WHITE}; color: {DARK}; }}\n",
        "    .topbar {{\n",
        "        background: {RED};\n",
        "        padding: 16px 18px;\n",
        "        border-radius: 14px;\n",
        "        color: {WHITE};\n",
        "        font-weight: 700;\n",
        "        font-size: 20px;\n",
        "        margin-bottom: 14px;\n",
        "    }}\n",
        "    .card {{\n",
        "        border: 1px solid rgba(0,0,0,0.10);\n",
        "        border-radius: 14px;\n",
        "        padding: 14px 14px;\n",
        "        background: {WHITE};\n",
        "    }}\n",
        "    .pill {{\n",
        "        display: inline-block;\n",
        "        padding: 6px 10px;\n",
        "        border-radius: 999px;\n",
        "        background: {SOFT_RED};\n",
        "        border: 1px solid rgba(193,18,31,0.18);\n",
        "        color: {RED};\n",
        "        font-weight: 600;\n",
        "        font-size: 12px;\n",
        "    }}\n",
        "    .answer {{\n",
        "        border-left: 6px solid {RED};\n",
        "        background: {SOFT_RED};\n",
        "        padding: 14px 14px;\n",
        "        border-radius: 12px;\n",
        "        white-space: pre-wrap;\n",
        "    }}\n",
        "    .question {{\n",
        "        border: 1px solid rgba(193,18,31,0.25);\n",
        "        background: {WHITE};\n",
        "        padding: 12px 12px;\n",
        "        border-radius: 12px;\n",
        "        white-space: pre-wrap;\n",
        "    }}\n",
        "\n",
        "    .stButton > button {{\n",
        "        background-color: #000000 !important;\n",
        "        color: #ffffff !important;\n",
        "        border-radius: 12px;\n",
        "        border: none;\n",
        "        font-weight: 700;\n",
        "    }}\n",
        "    .stButton > button:hover {{\n",
        "        background-color: #000000 !important;\n",
        "        color: #ffffff !important;\n",
        "    }}\n",
        "    .stButton > button:active {{\n",
        "        background-color: #000000 !important;\n",
        "        color: #ffffff !important;\n",
        "    }}\n",
        "    .stButton > button:focus {{\n",
        "        background-color: #000000 !important;\n",
        "        color: #ffffff !important;\n",
        "        outline: none;\n",
        "        box-shadow: none;\n",
        "    }}\n",
        "    </style>\n",
        "    \"\"\",\n",
        "    unsafe_allow_html=True,\n",
        ")\n",
        "\n",
        "st.markdown('<div class=\"topbar\">Hospital Management Chatbot</div>', unsafe_allow_html=True)\n",
        "\n",
        "with st.sidebar:\n",
        "    st.markdown(\"### Connections\")\n",
        "\n",
        "    real_host = st.text_input(\"Postgres host\", value=os.getenv(\"REAL_HOST\", \"\"))\n",
        "    real_port = st.text_input(\"Postgres port\", value=os.getenv(\"REAL_PORT\", \"\"))\n",
        "    pg_password = st.text_input(\"Postgres password\", value=os.getenv(\"PG_PASSWORD\", \"\"), type=\"password\")\n",
        "    pg_db = st.text_input(\"Database name\", value=os.getenv(\"PG_DB\", \"hospital\"))\n",
        "    pg_user = st.text_input(\"Database user\", value=os.getenv(\"PG_USER\", \"postgres\"))\n",
        "\n",
        "    milvus_uri = st.text_input(\"Milvus URI\", value=os.getenv(\"MILVUS_URI\", \"\"))\n",
        "    milvus_token = st.text_input(\"Milvus token\", value=os.getenv(\"MILVUS_TOKEN\", \"\"), type=\"password\")\n",
        "\n",
        "    gemini_key = st.text_input(\"Gemini API key\", value=os.getenv(\"GEMINI_API_KEY\", \"\"), type=\"password\")\n",
        "    gemini_model = st.text_input(\"Gemini model\", value=os.getenv(\"GEMINI_SQL_MODEL\", \"models/gemini-2.0-flash-lite-001\"))\n",
        "\n",
        "    st.markdown(\"### Hospital\")\n",
        "    hospital_id = st.selectbox(\"Hospital ID\", [1, 2], index=0)\n",
        "\n",
        "    apply_btn = st.button(\"Apply settings\")\n",
        "\n",
        "if apply_btn:\n",
        "    os.environ[\"REAL_HOST\"] = real_host.strip()\n",
        "    os.environ[\"REAL_PORT\"] = real_port.strip()\n",
        "    os.environ[\"PG_PASSWORD\"] = pg_password\n",
        "    os.environ[\"PG_DB\"] = pg_db.strip()\n",
        "    os.environ[\"PG_USER\"] = pg_user.strip()\n",
        "\n",
        "    os.environ[\"MILVUS_URI\"] = milvus_uri.strip()\n",
        "    os.environ[\"MILVUS_TOKEN\"] = milvus_token\n",
        "\n",
        "    os.environ[\"GEMINI_API_KEY\"] = gemini_key\n",
        "    os.environ[\"GEMINI_SQL_MODEL\"] = gemini_model.strip()\n",
        "\n",
        "    st.success(\"Settings applied. Now ask a question.\")\n",
        "\n",
        "import hospital_management_chatbot as backend\n",
        "from hospital_management_chatbot import chat\n",
        "\n",
        "@st.cache_resource\n",
        "def warmup():\n",
        "    backend.init_once(index=False)\n",
        "    return True\n",
        "\n",
        "try:\n",
        "    warmup()\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "\n",
        "def chat_with_timeout(q: str, hid: int, timeout_sec: int = 25) -> str:\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=1) as ex:\n",
        "        fut = ex.submit(chat, q, hid)\n",
        "        return fut.result(timeout=timeout_sec)\n",
        "\n",
        "\n",
        "if \"history\" not in st.session_state:\n",
        "    st.session_state.history = []\n",
        "\n",
        "st.markdown('<div class=\"card\">', unsafe_allow_html=True)\n",
        "question = st.text_area(\"Ask a question\", height=120)\n",
        "\n",
        "col1, col2 = st.columns(2)\n",
        "ask_btn = col1.button(\"Ask\")\n",
        "clear_btn = col2.button(\"Clear\")\n",
        "\n",
        "if clear_btn:\n",
        "    st.session_state.history = []\n",
        "    st.rerun()\n",
        "\n",
        "if ask_btn:\n",
        "    q = (question or \"\").strip()\n",
        "    if not q:\n",
        "        st.warning(\"Please type a question.\")\n",
        "    else:\n",
        "        with st.spinner(\"Working...\"):\n",
        "            try:\n",
        "                ans = chat_with_timeout(q, int(hospital_id), timeout_sec=25)\n",
        "            except concurrent.futures.TimeoutError:\n",
        "                ans = \"Error: Request timed out. Check Postgres, Milvus, or Gemini connectivity.\"\n",
        "            except Exception as e:\n",
        "                ans = f\"Error: {e}\"\n",
        "        st.session_state.history.append({\"ts\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"), \"q\": q, \"a\": ans})\n",
        "\n",
        "for item in reversed(st.session_state.history):\n",
        "    st.markdown(f'<div class=\"pill\">{item[\"ts\"]}</div>', unsafe_allow_html=True)\n",
        "    st.markdown(\"**Question**\")\n",
        "    st.markdown(f'<div class=\"question\">{item[\"q\"]}</div>', unsafe_allow_html=True)\n",
        "    st.markdown(\"**Answer**\")\n",
        "    st.markdown(f'<div class=\"answer\">{item[\"a\"]}</div>', unsafe_allow_html=True)\n",
        "    st.markdown(\"\")\n",
        "\n",
        "st.markdown(\"</div>\", unsafe_allow_html=True)\n",
        "'''\n",
        "with open(\"app.py\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(app_code)\n",
        "print(\"Wrote app.py\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Su39M_HP0bjc",
      "metadata": {
        "id": "Su39M_HP0bjc"
      },
      "source": [
        "## Run Streamlit\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "dGtTeDrj0bjd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGtTeDrj0bjd",
        "outputId": "9c8d27fb-6e10-49a1-8081-6dedc0c5551a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n",
            "Streamlit started. Logs: !tail -n 120 streamlit.log\n"
          ]
        }
      ],
      "source": [
        "!pkill -f streamlit || true\n",
        "!streamlit run app.py --server.port 8501 --server.address 0.0.0.0 --server.headless true --logger.level=debug > streamlit.log 2>&1 &\n",
        "print(\"Streamlit started. Logs: !tail -n 120 streamlit.log\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eFOuYatO0bjd",
      "metadata": {
        "id": "eFOuYatO0bjd"
      },
      "source": [
        "## Expose Streamlit with Cloudflared\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "LQIN3odS0bjd",
      "metadata": {
        "id": "LQIN3odS0bjd"
      },
      "outputs": [],
      "source": [
        "!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O /usr/local/bin/cloudflared\n",
        "!chmod +x /usr/local/bin/cloudflared\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "xmZgyybG0bjd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmZgyybG0bjd",
        "outputId": "ff36c756-33d5-4fa8-f90e-6270a853cbd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Open this URL: https://april-unlike-flat-textiles.trycloudflare.com\n"
          ]
        }
      ],
      "source": [
        "import subprocess, re, time\n",
        "\n",
        "p = subprocess.Popen(\n",
        "    [\"cloudflared\", \"tunnel\", \"--url\", \"http://localhost:8501\"],\n",
        "    stdout=subprocess.PIPE,\n",
        "    stderr=subprocess.STDOUT,\n",
        "    text=True\n",
        ")\n",
        "\n",
        "url = None\n",
        "start = time.time()\n",
        "while time.time() - start < 30:\n",
        "    line = p.stdout.readline().strip()\n",
        "    m = re.search(r\"(https://[a-zA-Z0-9\\-]+\\.trycloudflare\\.com)\", line)\n",
        "    if m:\n",
        "        url = m.group(1)\n",
        "        break\n",
        "\n",
        "print(\"Open this URL:\", url if url else \"Not found. Check logs with: !tail -n 200 streamlit.log\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yfIouBhv0bjd",
      "metadata": {
        "id": "yfIouBhv0bjd"
      },
      "source": [
        "## Debug Streamlit if stuck\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "GmWAoWOw0bjd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmWAoWOw0bjd",
        "outputId": "886acbbc-df42-4a65-b024-ca21b472c2e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\n",
            "2025-12-23 06:17:18.386 Filtered 741 packages down to 2 candidates for component scanning\n",
            "2025-12-23 06:17:18.386 Scanning 2 candidate packages for component manifests using 2 worker threads\n",
            "2025-12-23 06:17:18.418 Found 0 component manifests total\n",
            "2025-12-23 06:17:18.418 No asset roots to watch\n",
            "2025-12-23 06:17:18.419 File watching not started\n",
            "2025-12-23 06:17:18.419 Starting new event loop for server\n",
            "2025-12-23 06:17:18.419 Starting server...\n",
            "2025-12-23 06:17:18.687 Serving static content from /usr/local/lib/python3.12/dist-packages/streamlit/static\n",
            "2025-12-23 06:17:18.689 Server started on port 8501\n",
            "2025-12-23 06:17:18.690 Runtime state: RuntimeState.INITIAL -> RuntimeState.NO_SESSIONS_CONNECTED\n",
            "\n",
            "  You can now view your Streamlit app in your browser.\n",
            "\n",
            "  URL: http://0.0.0.0:8501\n",
            "\n",
            "2025-12-23 06:17:18.691 Setting up signal handler\n"
          ]
        }
      ],
      "source": [
        "!tail -n 200 streamlit.log\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
